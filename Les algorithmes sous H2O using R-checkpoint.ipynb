{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script:\n",
    "#   des algorithmes Random Forest (RF) Gradient Boosting (GBM),\n",
    "#   extrem Gradient Boosting (XGB) et Deep learning (DL) Sous H2O avec R\n",
    "\n",
    "# Description:\n",
    "# Ce script est dédié au développement des algorithme RF, GBM, XGB et DL,\n",
    "# le développement de ces algorithme suit étapes suivant:\n",
    "#         1- Importation du Paquet H2O et le démarré\n",
    "#         2- Importation des données et spécification des variables \n",
    "#            indépendants et dépendant;\n",
    "#         3- Création de la fonction d'évaluation \n",
    "#             (Pour calculer les indice de pérformance);\n",
    "#         4- Développement et l'évaluation des 4 algorithmes:\n",
    "#             4-1) Avec les paramètres par défaut;\n",
    "#             4-2) Avec les paramètres optimisé par RandomDiscrit \n",
    "#                  (Random Searche);\n",
    "#             4-3) Avec les paramètres optimisé par Cartesien \n",
    "#                  (Grid Search).\n",
    "\n",
    "# Version:\n",
    "#     Mohammed AMEKSA:       Juin 2019       Script Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer la bibliothèque H2O et le démarré \n",
    "## Puis l'importation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(h2o)\n",
    "# Démarage de h2o\n",
    "h2o.init(\n",
    "  ip = 'localhost', # addresse local du machine\n",
    "  port = 54321,\n",
    "  nthreads = -1,      ## -1: pour l'utilisation de tous les threads\n",
    "  max_mem_size = \"8g\" ## Spécification de la taille mémoire H2O cloud\n",
    ")\n",
    "h2o.removeAll() # Au cas où le cluster fonctionnait déjà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importer les deux fichiers de données\n",
    "#spécifier le chemine ou se trouvent \n",
    "meteo_train_path <- \"Stage DMN/Train-Equil-Lon-Lat-Hour-Month-RedVisi.csv\"\n",
    "meteo_test_path <- \"Stage DMN/Test-Equil-Lon-Lat-Hour-Month-RedVisi.csv\"\n",
    "\n",
    "# importer les données de disque au h2o\n",
    "meteo_train<-h2o.importFile(path = meteo_train_path, \n",
    "                            destination_frame = \"meteo_train.hex\")\n",
    "meteo_test<-h2o.importFile(path = meteo_test_path, \n",
    "                           destination_frame = \"meteo_test.hex\")\n",
    "\n",
    "# variable target (Visibilite)\n",
    "y.dep <- 35\n",
    "# variables independent\n",
    "x.indep <- c(1:34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des fonctions d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaliation <- function(model) {\n",
    "    print(\"-----  H2o model : -----\")\n",
    "    print(\"Comparaison de la performance pour les donnée Train & Test\")\n",
    "    PredTest <- as.data.frame(h2o.predict(model, meteo_test))\n",
    "    PredTrain <- as.data.frame(h2o.predict(model, meteo_train))\n",
    "\n",
    "    ActualTrain=as.data.frame(meteo_train['Visibilite'])\n",
    "    ActualTest=as.data.frame(meteo_test['Visibilite'])\n",
    "\n",
    "    TestbothPA=cbind(PredTest,ActualTest)\n",
    "    BIAS <- round(mean(TestbothPA[,1] - TestbothPA[,2]),4)\n",
    "    RMSE <-  round(sqrt(mean((TestbothPA[,1] - TestbothPA[,2])^2)),4)\n",
    "    MAE <- round(mean(abs(TestbothPA[,1] - TestbothPA[,2])),4)\n",
    "    CC <- round(cor(TestbothPA[,1],TestbothPA[,2]),4)\n",
    "    set <- \"Test\"\n",
    "    errors.test <- data.frame(set,BIAS,RMSE,MAE,CC)\n",
    "\n",
    "    TrainbothPA=cbind(PredTrain,ActualTrain)\n",
    "    BIAS <- round(mean(TrainbothPA[,1] - TrainbothPA[,2]),4)\n",
    "    RMSE <-  round(sqrt(mean((TrainbothPA[,1] - TrainbothPA[,2])^2)),4)\n",
    "    MAE <- round(mean(abs(TrainbothPA[,1] - TrainbothPA[,2])),4)\n",
    "    CC <- round(cor(TrainbothPA[,1],TrainbothPA[,2]),4)\n",
    "    set <- \"Train\"\n",
    "    errors.train <- data.frame(set,BIAS,RMSE,MAE,CC)\n",
    "\n",
    "    Eval.metrics=rbind(errors.train,errors.test)\n",
    "    print('======================================')\n",
    "    print(Eval.metrics)\n",
    "\n",
    "    print(\"----- H2o model : check variable importance -----\")\n",
    "    #check variable importance\n",
    "    VarImpo <- h2o.varimp(model)\n",
    "    #print(VarImpo)\n",
    "    h2o.varimp_plot(model)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Méthodes Ensemblistes\n",
    "## Random Forest\n",
    "### Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle RF par défauts\n",
    "rforest.defaut <- h2o.randomForest(y=y.dep, \n",
    "                                x=x.indep, \n",
    "                                training_frame = meteo_train,\n",
    "                                validation_frame = meteo_test,\n",
    "                                model_id=\"rf_defaut\", \n",
    "                                seed = 42, )\n",
    "# évaluation du modèle\n",
    "Evaliation(rforest.defaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres avec Grid Search et Random Search\n",
    "**les hyperparamètres les plus importants choisis pour Random forest sont:**\n",
    "* ntrees = nombre d'arbres, \n",
    "* mtries = le nombre de colonnes à sélectionner au hasard à chaque niveau, \n",
    "* max_depth = profondeur maximale de chaque arbre,\n",
    "* min_rows = le nombre minimum d'observations pour une feuille,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params <- list(ntrees = seq(50, 100, 10),\n",
    "                 max_depth = seq(10, 17, 1),\n",
    "                 min_rows= seq(1, 5, 1),\n",
    "                 mtries = seq(-1, 3, 1))\n",
    "search_criteria <- list(strategy = \"RandomDiscrete\", \n",
    "                        max_models = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_RandomDiscrete <- h2o.grid(\"drf\",\n",
    "                              y=y.dep, \n",
    "                              x=x.indep,\n",
    "                              grid_id = \"rf_RandomDiscrete\",\n",
    "                              training_frame = meteo_train,\n",
    "                              validation_frame = meteo_test,\n",
    "                              seed = 1,\n",
    "                              hyper_params = rf_params,\n",
    "                              search_criteria = search_criteria)\n",
    "# on trie les résultats par mae\n",
    "perf_rf_RandomDiscrete <- h2o.getGrid(grid_id = \"rf_RandomDiscrete\", \n",
    "                           sort_by = \"mae\", \n",
    "                           decreasing = FALSE)\n",
    "# Puis on garder le premier (c-à-d qu'il a le minimum des erreurs)\n",
    "rf_RandomDiscrete_selectione = h2o.getModel(perf_rf_RandomDiscrete@model_ids[[1]])\n",
    "# et on évaluer le modèle\n",
    "Evaliation(rf_RandomDiscrete_selectione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gride search et par défauts\n",
    "rf_Cartesient <- h2o.grid(\"drf\", x=1:34, y=35,\n",
    "                    grid_id = \"rf_Cartesient\",\n",
    "                    training_frame = meteo_train,\n",
    "                    validation_frame = meteo_test,\n",
    "                    seed = 1,\n",
    "                    hyper_params = rf_params)\n",
    "# on trie les résultats par mae\n",
    "perf_rf_Cartesient <- h2o.getGrid(grid_id = \"rf_Cartesient\", \n",
    "                           sort_by = \"mae\", \n",
    "                           decreasing = FALSE)\n",
    "# Puis on garder le premier (c-à-d qu'il a le minimum des erreurs)\n",
    "rf_Cartesient_selectione = h2o.getModel(perf_rf_Cartesient@model_ids[[1]])\n",
    "# et on évaluer le modèle\n",
    "Evaliation(rf_Cartesient_selectione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "### Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.defaut <- h2o.gbm( y=y.dep, \n",
    "               x=x.indep, \n",
    "               training_frame = meteo_train,\n",
    "               validation_frame = meteo_test,\n",
    "               model_id=\"gbm_defaut\", \n",
    "               seed = 42, )\n",
    "# évaluation du modèle\n",
    "Evaliation(gbm.defaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres avec Grid Search et Random Search\n",
    "**les hyperparamètres les plus importants choisis pour Gradient Boosting Machine sont:**\n",
    "* ntrees = nombre d'arbres, \n",
    "* max_depth = profondeur maximale de chaque arbre,\n",
    "* sample_rate = spécifier le taux d'échantillonnage de la ligne (sans remplacement).\n",
    "* min_rows = le nombre minimum d'observations pour une feuille,\n",
    "* learn_rate = taux d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params <- list(ntrees = seq(200, 400 , 50),\n",
    "                    max_depth = seq(11, 17, 2),\n",
    "                    sample_rate = c(0.5, 0.8, 0.95, 1.0),\n",
    "                    min_rows = c(2, 5, 10),\n",
    "                    learn_rate = c(0.1))\n",
    "search_criteria <- list(strategy = \"RandomDiscrete\", \n",
    "                        max_models = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_RandomDiscrete <- h2o.grid(\"gbm\", x=x.indep, y=y.dep,\n",
    "                      grid_id = \"gbm_RandomDiscrete\",\n",
    "                      training_frame = meteo_train,\n",
    "                      validation_frame = meteo_test,\n",
    "                      seed = 1,\n",
    "                      hyper_params = gbm_params,\n",
    "                      search_criteria = search_criteria,\n",
    "                      stopping_tolerance = 0.001,\n",
    "                      stopping_rounds=3,\n",
    "                      score_tree_interval = 10 )\n",
    "# on trie les résultats par mae\n",
    "perf_gbm_RandomDiscrete <- h2o.getGrid(grid_id = \"gbm_RandomDiscrete\", \n",
    "                             sort_by = \"mae\", \n",
    "                             decreasing = FALSE)\n",
    "# Puis on garder le premier (c-à-d qu'il a le minimum des erreurs)\n",
    "gbm_gs_selected=h2o.getModel(perf_gbm_RandomDiscrete@model_ids[[1]])\n",
    "# et on évaluer le modèle\n",
    "Evaliation(gbm_gs_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate a grid of GBM\n",
    "gbm_cartesien<- h2o.grid(\"gbm\", x=x.indep, y=y.dep,\n",
    "                      grid_id = \"gbm_cartesien\",\n",
    "                      training_frame = meteo_train,\n",
    "                      validation_frame = meteo_test,\n",
    "                      seed = 1,\n",
    "                      hyper_params = gbm_params)\n",
    "# on trie les résultats par mae\n",
    "perf_gbm_cartesien <- h2o.getGrid(grid_id = \"gbm_cartesien\", \n",
    "                             sort_by = \"mae\", \n",
    "                             decreasing = FALSE)\n",
    "# Puis on garder le premier (c-à-d qu'il a le minimum des erreurs)\n",
    "gbm_cartesien=h2o.getModel(perf_gbm_random_search@model_ids[[1]])\n",
    "# et on évaluer le modèle\n",
    "Evaliation(gbm_cartesien)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXtrem Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour xgboost nous avons le développé dans une autre machine\n",
    "# pour cela nous avons lancé h2o dans une machine \n",
    "# Puis nous avons fait l'accé a cette machine via l'adresse IP\n",
    "library(h2o)\n",
    "#Start H2O \n",
    "h2o.init(\n",
    "  ip = 192.168.132.128,\n",
    "  port = 54321,\n",
    "  nthreads = -1,     \n",
    "  max_mem_size = \"8g\" \n",
    ")\n",
    "h2o.removeAll() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les chemines des deux fichiers de données \n",
    "meteo_train_path <- \"C:/Users/Stage DMN/Train-Equil-Lon-Lat-Hour-Month-RedVisi.csv\"\n",
    "meteo_test_path <- \"C:/Users/Stage DMN/Test-Equil-Lon-Lat-Hour-Month-RedVisi.csv\"\n",
    "\n",
    "# puisque nous avons lancé h2o dans une autre machine \n",
    "# ici nous avons utilisé uploadFile au lieu d'importFile\n",
    "meteo_train<-h2o.uploadFile(path = meteo_train_path, \n",
    "                            destination_frame = \"meteo_train.hex\")\n",
    "meteo_test<-h2o.uploadFile(path = meteo_test_path, \n",
    "                           destination_frame = \"meteo_test.hex\")\n",
    "\n",
    "# variable target (Visibilite)\n",
    "y.dep <- 35\n",
    "# variables independents\n",
    "x.indep <- c(1:34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.defaut<-h2o.xgboost(y=y.dep, \n",
    "               x=x.indep, \n",
    "               training_frame =train,\n",
    "               validation_frame=test,\n",
    "               model_id=\"Xgboost_defaut\",\n",
    "               seed = 1)\n",
    "# évaluation du modèle\n",
    "Evaliation(xgb.defaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres avec Grid Search et Random Search\n",
    "**les hyperparamètres les plus importants choisis pour Gradient Boosting Machine sont:**\n",
    "* max_depth = profondeur maximale de chaque arbre\n",
    "* min_rows = le nombre minimum d'observations pour une feuille,\n",
    "* sample_rate = spécifier le taux d'échantillonnage de la ligne (axe des x) (sans remplacement).\n",
    "* col_sample_rate et  col_sample_rate_per_tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params <- list(max_depth = c(5, 10, 17),\n",
    "                min_rows = c(2, 5, 11),\n",
    "                sample_rate = c(0.5, 0.8, 0.95, 1.0),\n",
    "                col_sample_rate = c(0.5, 0.8, 0.95, 1.0),\n",
    "                col_sample_rate_per_tree = c(0.8, 0.99, 1.0))\n",
    "xgb_search_criteria <- list(strategy = \"RandomDiscrete\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_RandomDiscrete = h2o.grid(grid_id =\"xgb_randomDiscrete\",\n",
    "                    x=x.indep, y=y.dep,\n",
    "                    hyper_params = xgb_params,\n",
    "                    search_criteria = xgb_search_criteria,\n",
    "                    training_frame = meteo_train,\n",
    "                    validation_frame = meteo_test,\n",
    "            \n",
    "                    stopping_tolerance = 0.001,\n",
    "                    stopping_rounds=3,\n",
    "                    score_tree_interval = 10,\n",
    "                    ntrees = 400) \n",
    "# on trie les résultats par mae\n",
    "xgb_perf_RandomDiscrete <- h2o.getGrid(grid_id = \"xgb_randomDiscrete\", \n",
    "                             sort_by = \"mae\", \n",
    "                             decreasing = FALSE)\n",
    "# Puis on garder le premier (c-à-d qu'il a le minimum des erreurs)\n",
    "RS_xgb <- h2o.getModel(xgb_perf_RandomDiscrete@model_ids[[1]])\n",
    "# évaluation du modèle\n",
    "Evaliation(RS_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cartesien = h2o.grid(grid_id =\"xgb_cartesien\",\n",
    "                    x=x.indep, y=y.dep,\n",
    "                    hyper_params = xgb_params,\n",
    "                    training_frame = meteo_train,\n",
    "                    validation_frame = meteo_test,\n",
    "            \n",
    "                    stopping_tolerance = 0.001,\n",
    "                    stopping_rounds=3,\n",
    "                    score_tree_interval = 10,\n",
    "                    ntrees = 400) \n",
    "# on trie les résultats par mae\n",
    "xgb_perf_cartesien <- h2o.getGrid(grid_id = \"xgb_cartesien\", \n",
    "                             sort_by = \"mae\", \n",
    "                             decreasing = FALSE)\n",
    "# Puis on garder le premier (c-à-d qu'il a le minimum des erreurs)\n",
    "GS_xgb <- h2o.getModel(xgb_perf_cartesien@model_ids[[1]])\n",
    "# évaluation du modèle\n",
    "Evaliation(GS_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Apprentissage profond\n",
    "### Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlearning.defaut <- h2o.deeplearning(model_id=\"dlearning_defaut\",\n",
    "                                     x=x.indep, y=y.dep,\n",
    "                                training_frame =meteo_train, \n",
    "                                validation_frame = meteo_test,\n",
    "                                model_id=\"dlearning_defaut\", )\n",
    "# évaluation du modèle\n",
    "Evalution(dlearning.defaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlearning_manuel <- h2o.deeplearning(model_id=\"dlearning_manuel\",\n",
    "                                     x=x.indep, y=y.dep,\n",
    "                                training_frame =meteo_train, \n",
    "                                validation_frame = meteo_test,\n",
    "                                epoch = 100,\n",
    "                                hidden = c(68,68), # 2 couches cachées\n",
    "                                activation = \"Rectifier\", )\n",
    "# évaluation du modèle\n",
    "Evaliation(dlearning_manuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
